{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "start_year = 2013\n",
    "end_year = 2023\n",
    "\n",
    "movies_data_by_year = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(year):\n",
    "    data_common_name = 'prepared_data/tmdb_dump'\n",
    "    return f'{data_common_name}-{year}.csv'\n",
    "\n",
    "def read_data_set(year):\n",
    "    file_path = get_file_path(year)\n",
    "    return pd.read_csv(file_path, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(start_year, end_year+1):\n",
    "    data = read_data_set(year)\n",
    "    movies_data_by_year[year] = data\n",
    "    if 'all' in movies_data_by_year:\n",
    "        movies_data_by_year['all'] = pd.concat([movies_data_by_year['all'], data])\n",
    "    else:\n",
    "        movies_data_by_year['all'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos Dados numéricos (Quantidade e Média)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies_count(year):\n",
    "    df =  movies_data_by_year[year]\n",
    "    return len(df.index)\n",
    "\n",
    "def budget_mean(year):\n",
    "    df: DataFrame = movies_data_by_year[year]\n",
    "    return df.loc[:, 'budget'].mean()\n",
    "\n",
    "def revenue_mean(year):\n",
    "    df: DataFrame = movies_data_by_year[year]\n",
    "    return df.loc[:, 'revenue'].mean()\n",
    "\n",
    "def runtime_mean(year):\n",
    "    df: DataFrame = movies_data_by_year[year]\n",
    "    return df.loc[:, 'runtime'].mean()\n",
    "\n",
    "def vote_count_mean(year):\n",
    "    df: DataFrame = movies_data_by_year[year]\n",
    "    return df.loc[:, 'vote_count'].mean()\n",
    "\n",
    "def vote_mean_by_year(year):\n",
    "    df: DataFrame = movies_data_by_year[year]\n",
    "    return vote_mean(df)\n",
    "\n",
    "def vote_mean(df):\n",
    "    df[\"weight\"] = df[\"vote_count\"] * df[\"vote_average\"]\n",
    "    return df[\"weight\"].sum() / df[\"vote_count\"].sum()\n",
    "    \n",
    "def vote_deviation(df):\n",
    "    mean = vote_mean(df)\n",
    "    df[\"weight\"] = df[\"vote_count\"] * df[\"vote_average\"]    \n",
    "    df[\"deviation\"] = ((df[\"vote_average\"] - mean)**2) * df[\"weight\"]\n",
    "    \n",
    "    upper_eq_part = df[\"deviation\"].sum()\n",
    "    \n",
    "    weight_sum = df[\"weight\"].sum()\n",
    "    n = df[\"weight\"].count()\n",
    "    bottom_eq_part = weight_sum * (n - 1) / n\n",
    "    \n",
    "    return math.sqrt(upper_eq_part/bottom_eq_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo do desvio padrão amostral dos dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget        5.004297e+07\n",
      "revenue       2.163519e+08\n",
      "runtime       2.107148e+01\n",
      "vote_count    3.680442e+03\n",
      "dtype: float64\n",
      "Deviation:  0.7151867182957711\n"
     ]
    }
   ],
   "source": [
    "df_concat = movies_data_by_year[start_year]\n",
    "for year in range(start_year+1, end_year+1):\n",
    "    df_concat = pd.concat([df_concat, movies_data_by_year[year]])\n",
    "    \n",
    "numeric_columns = [\"budget\", \"revenue\", \"runtime\", \"vote_count\"]\n",
    "print(df_concat[numeric_columns].std())\n",
    "print(\"Deviation: \", vote_deviation(df_concat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013.00  & 333.00  & 29133697.35  & 83963872.83  & 111.97  & 2356.57  & 6.79  & \n",
      "2014.00  & 317.00  & 27739095.79  & 88809630.21  & 109.73  & 2624.77  & 7.01  & \n",
      "2015.00  & 301.00  & 28413424.29  & 96225236.56  & 112.00  & 2407.86  & 6.81  & \n",
      "2016.00  & 339.00  & 30959884.17  & 92686166.47  & 111.99  & 2464.51  & 6.83  & \n",
      "2017.00  & 307.00  & 29728204.99  & 103942389.76  & 112.44  & 2593.88  & 6.96  & \n",
      "2018.00  & 275.00  & 30404534.53  & 109654092.13  & 112.82  & 2334.57  & 7.00  & \n",
      "2019.00  & 251.00  & 32862991.07  & 119087300.21  & 111.95  & 2376.76  & 7.14  & \n",
      "2020.00  & 132.00  & 26047200.65  & 39661077.16  & 105.89  & 1539.45  & 7.04  & \n",
      "2021.00  & 158.00  & 45537524.30  & 93868823.13  & 115.16  & 2124.64  & 7.21  & \n",
      "2022.00  & 173.00  & 39368203.98  & 105105561.14  & 115.13  & 1499.87  & 7.11  & \n",
      "2023.00  & 207.00  & 44851926.51  & 106455189.39  & 117.57  & 1097.42  & 7.14  & \n"
     ]
    }
   ],
   "source": [
    "for year in range(start_year, end_year+1):\n",
    "    values = year, movies_count(year), budget_mean(year), revenue_mean(year), runtime_mean(year), vote_count_mean(year), vote_mean_by_year(year)\n",
    "    for value in values:\n",
    "        print(\"{:.2f}\".format(value), \" & \" , end=\"\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograma das variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data, title, xlabel):\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.histplot(y=data, stat=\"count\", bins=(len(data.unique())))\n",
    "    # plt.xscale('log')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Frequência\")\n",
    "    plt.show()\n",
    "    \n",
    "df = movies_data_by_year[2013]\n",
    "\n",
    "# Histograma para production_countries\n",
    "df['production_countries'] = df['production_countries'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# df_countries = df.explode('production_countries', ignore_index=True)[\"production_countries\"]\n",
    "# plot_histogram(df_countries, 'Distribuição de Production Countries', 'Países Produtores')\n",
    "\n",
    "# # Histograma para genres\n",
    "# df['genres'] = df['genres'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# df_genres = df.explode('genres')['genres']\n",
    "# plot_histogram(df_genres, 'Distribuição de Genres', 'Gêneros')\n",
    "\n",
    "# # Histograma para keywords\n",
    "# df['keywords'] = df['keywords'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# df_keywords = df.explode('keywords')['keywords']\n",
    "# plot_histogram(df_keywords, 'Distribuição de Keywords', 'Palavras-Chave')\n",
    "\n",
    "# # Histograma para spoken_languages\n",
    "# df['spoken_languages'] = df['spoken_languages'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "# df_languages = df.explode('spoken_languages')['spoken_languages']\n",
    "# plot_histogram(df_languages, 'Distribuição de Spoken Languages', 'Línguas Faladas')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for year in range(start_year, end_year+1):\n",
    "#     df = movies_data_by_year[year]\n",
    "#     all_countries = [country for sublist in df['production_countries'] for country in ast.literal_eval(sublist)]\n",
    "#     # # Count the occurrences of each country\n",
    "#     country_counts = Counter(all_countries)\n",
    "\n",
    "#     # Convert to DataFrame for better visualization (optional)\n",
    "#     country_counts_df = pd.DataFrame.from_dict(country_counts, orient='index', columns=['count']).reset_index()\n",
    "#     country_counts_df.rename(columns={'index': 'country'}, inplace=True)\n",
    "#     print(year)\n",
    "#     print(country_counts_df.sort_values(by=\"count\", ascending=False).head(15))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Países que não correspondem no GeoJSON:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium import Choropleth\n",
    "\n",
    "for year in range (start_year, end_year+1):\n",
    "    df = movies_data_by_year[year]\n",
    "    df['production_countries'] = df['production_countries'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "    df_countries = df.explode('production_countries', ignore_index=True)\n",
    "    country_counts = df_countries['production_countries'].value_counts().reset_index()\n",
    "    country_counts.columns = ['production_country', 'count']\n",
    "    country_counts['count'] = np.log(country_counts['count'])\n",
    "\n",
    "    # Carrega o arquivo GeoJSON com as fronteiras dos países\n",
    "    geo_json_data = gpd.read_file('https://raw.githubusercontent.com/johan/world.geo.json/master/countries.geo.json')\n",
    "\n",
    "    # Renomeia as colunas para corresponder aos nomes do GeoJSON\n",
    "    geo_json_data = geo_json_data.rename(columns={\"name\": \"production_country\"})\n",
    "\n",
    "    geo_countries_list = geo_json_data[\"production_country\"].tolist()\n",
    "   \n",
    "    country_mapping = {\n",
    "        'Hong Kong': 'China',  # Considera Hong Kong como parte da China\n",
    "        'Serbia': 'Republic of Serbia',\n",
    "        'Aruba': 'Netherlands',  # Considera Aruba como parte dos Países Baixos\n",
    "        'Singapore': 'Malaysia',\n",
    "        'Congo': 'Democratic Republic of the Congo',\n",
    "        'Bahamas': 'The Bahamas',\n",
    "        'Guadaloupe': 'France' # Considera Guadalupe como parte da frança\n",
    "    }\n",
    "\n",
    "    country_counts.replace(country_mapping, inplace=True)\n",
    "    \n",
    "    df_countries_list = country_counts['production_country'].tolist()\n",
    "    missing_countries = [country for country in df_countries_list if country not in geo_countries_list]\n",
    "\n",
    "    # Exibe os países que não têm correspondência\n",
    "    print(\"Países que não correspondem no GeoJSON:\")\n",
    "    print(missing_countries)\n",
    "    \n",
    "\n",
    "    # Inicializa o mapa\n",
    "    m = folium.Map(location=[45, -90], zoom_start=1.5)\n",
    "\n",
    "    # Adiciona o choropleth map ao mapa\n",
    "    Choropleth(\n",
    "        geo_data=geo_json_data,\n",
    "        name='choropleth',\n",
    "        data=country_counts,\n",
    "        columns=['production_country', 'count'],\n",
    "        key_on='feature.properties.production_country',\n",
    "        fill_color='YlGn',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='Log(Número de Filmes por País)',\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Adiciona os controles de camada\n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    # Exibe o mapa\n",
    "    m.save(f'choropleth/choropleth_paises_produtores-{year}.html')\n",
    "    m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
